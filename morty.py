import json
import queue
import random
import requests
import sounddevice as sd
import pyttsx3
from vosk import Model, KaldiRecognizer
import json
import queue
import random
import requests
import sounddevice as sd
import pyttsx3
import webbrowser
import time
from vosk import Model, KaldiRecognizer

# –ú–æ–¥–µ–ª—å Vosk
model = Model("model")
recognizer = KaldiRecognizer(model, 16000)
q = queue.Queue()

# TTS
engine = pyttsx3.init()
engine.setProperty('rate', 170)

# –§–ª–∞–≥–∏ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
is_speaking = False
last_response_time = 0
last_response = ("", "")

# —Ñ—Ä–∞–∑—ã
MORTY_PHRASES = {
    'greeting': [
        "–≠-—ç–º... –ø—Ä–∏–≤–µ—Ç, –†–∏–∫! –Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ... –Ω–∞–≤–µ—Ä–Ω–æ–µ",
        "–û–∫–µ–π, —è –≤–∫–ª—é—á–∏–ª—Å—è... —Ç–æ–ª—å–∫–æ –Ω–µ –æ—Ä–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
        "–°–Ω–æ–≤–∞ —Ä–∞–±–æ—Ç–∞–µ–º? –õ–∞–¥–Ω–æ... —è –≥–æ—Ç–æ–≤, –≤—Ä–æ–¥–µ"
    ],
    'error': [
        "–ß-—á—Ç–æ? –Ø –Ω–µ –ø–æ–Ω—è–ª... –ø–æ–≤—Ç–æ—Ä–∏ –º–µ–¥–ª–µ–Ω–Ω–µ–µ!",
        "–≠-—ç—Ç–æ –≤–æ–æ–±—â–µ –ø–æ-—Ä—É—Å—Å–∫–∏? –Ø –∑–∞–ø—É—Ç–∞–ª—Å—è...",
        "–†–∏–∫, —è –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å... –º–æ–∂–µ—Ç, –ø–æ–≤—Ç–æ—Ä–∏—à—å?"
    ],
    'result': [
        "–í–æ—Ç —á—Ç–æ —è –Ω–∞—à—ë–ª: {result}... —ç—Ç–æ —Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ?",
        "–ö–∞–∂–µ—Ç—Å—è, —ç—Ç–æ {result}... –Ω–∞–¥–µ—é—Å—å, —è –Ω–µ –æ—à–∏–±—Å—è",
        "–°–º–æ—Ç—Ä–∏, –†–∏–∫! {result}... –∫—Ä—É—Ç–æ, –¥–∞?"
    ],
    'action': [
        "–î–µ–ª–∞—é... —ç-—ç–º... —Ç–æ–ª—å–∫–æ –Ω–µ –≤–∑–æ—Ä–≤–∏ –Ω–∏—á–µ–≥–æ!",
        "–ü—ã—Ç–∞—é—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å... –æ –±–æ–∂–µ, —ç—Ç–æ —Å—Ç—Ä–∞—à–Ω–æ",
        "–©–∞ —Å–¥–µ–ª–∞—é... –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ —É–±–∏–≤–∞–π –º–µ–Ω—è"
    ],
    'exit': [
        "–§—É—Ö... –Ω–∞–∫–æ–Ω–µ—Ü-—Ç–æ –∑–∞–∫–æ–Ω—á–∏–ª–∏! –Ø —É—Å—Ç–∞–ª...",
        "–í—ã—Ä—É–±–∞—é—Å—å... –µ—Å–ª–∏ —á—Ç–æ, —è –≤ —Å–≤–æ–µ–π –∫–æ–º–Ω–∞—Ç–µ",
        "–ü–æ–∫–∞, –†–∏–∫! –ù–∞–¥–µ—é—Å—å, —è –Ω–µ –Ω–∞–∫–æ—Å—è—á–∏–ª..."
    ]
}

def get_input_device():
    devices = sd.query_devices()
    input_devices = []
    for i, d in enumerate(devices):
        if d['max_input_channels'] > 0:
            print(f"{i}: {d['name']}")
            input_devices.append(i)
    
    if not input_devices:
        raise ValueError("No input devices found!")
    
    choice = int(input("–í—ã–±–µ—Ä–∏—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω: "))
    return choice

def callback(indata, frames, time, status):
    global is_speaking
    if not is_speaking:
        data = bytes(indata)
        if recognizer.AcceptWaveform(data):
            result = recognizer.Result()
            text = json.loads(result)["text"]
            q.put(text)

# –ì–æ–≤–æ—Ä–∏—Ç –ú–æ—Ä—Ç–∏
def say_morty(key, result=None):
    global is_speaking, last_response_time, last_response
    is_speaking = True
    
    phrase = random.choice(MORTY_PHRASES[key])
    if result:
        phrase = phrase.format(result=result)
        last_response = (key, result)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç
    
    print("üó£", phrase)
    engine.say(phrase)
    engine.runAndWait()
    
    is_speaking = False
    last_response_time = time.time()


#  –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –ú–æ—Ä—Ç–∏
class MortyAssistant:
    def __init__(self):
        self.current_character = {}

    def random_character(self):
        say_morty('action')
        char_id = random.randint(1, 826)
        res = requests.get(f"https://rickandmortyapi.com/api/character/{char_id}").json()
        self.current_character = res
        say_morty('result', result=res['name'])

    def show_image(self):
        say_morty('action')
        webbrowser.open(self.current_character["image"])

    def save_image(self):
        say_morty('action')
        img_data = requests.get(self.current_character["image"]).content
        with open("character.png", "wb") as f:
            f.write(img_data)
        say_morty('result', result="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")

    def first_episode(self):
        say_morty('action')
        first_ep = self.current_character["episode"][0]
        ep_data = requests.get(first_ep).json()
        say_morty('result', result=ep_data["name"])

    def get_resolution(self):
        say_morty('action')
        from PIL import Image
        from io import BytesIO
        img_data = requests.get(self.current_character["image"]).content
        img = Image.open(BytesIO(img_data))
        res = f"{img.width} –Ω–∞ {img.height} –ø–∏–∫—Å–µ–ª–µ–π"
        say_morty('result', result=res)

    def handle_command(self, command):
        cmd = command.lower()
        if '—Å–ª—É—á–∞–π–Ω—ã–π' in cmd:
            self.random_character()
        elif '–ø–æ–∫–∞–∑–∞—Ç—å' in cmd and self.current_character:
            self.show_image()
        elif '—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å' in cmd and self.current_character:
            self.save_image()
        elif '—ç–ø–∏–∑–æ–¥' in cmd and self.current_character:
            self.first_episode()
        elif '—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ' in cmd and self.current_character:
            self.get_resolution()
        elif '—Å—Ç–∞—Ç—É—Å' in cmd and self.current_character:
            status = self.current_character.get('status', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')
            say_morty('result', result=f"–µ–≥–æ —Å—Ç–∞—Ç—É—Å ‚Äî {status}")
        elif '–ª–æ–∫–∞—Ü–∏—è' in cmd and self.current_character:
            location = self.current_character.get('location', {}).get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ª–æ–∫–∞—Ü–∏—è')
            say_morty('result', result=f"–æ–Ω –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ {location}")
        elif '–≥–¥–µ –æ–Ω –±—ã–ª' in cmd and self.current_character:
            episodes = self.current_character.get('episode', [])
            num = len(episodes)
            say_morty('result', result=f"–æ–Ω –ø–æ—è–≤–∏–ª—Å—è –≤  {num} —ç–ø–∏–∑–æ–¥–∞—Ö")
        elif '–≤—ã—Ö–æ–¥' in cmd or '—Å—Ç–æ–ø' in cmd:
            say_morty('exit')
            return False
        else:
            say_morty('error')
        return True
    
# –ó–∞–≥—Ä—É–∑–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –º–æ–¥–µ–ª–∏
model = Model("model")  # –ø—É—Ç—å –∫ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ –º–æ–¥–µ–ª–∏
recognizer = KaldiRecognizer(model, 16000)
q = queue.Queue()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
engine = pyttsx3.init()
engine.setProperty('rate', 170)

# –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
current_character = {}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
def callback(indata, frames, time, status):
    data = bytes(indata)
    if recognizer.AcceptWaveform(data):
        result = recognizer.Result()
        text = json.loads(result)["text"]
        q.put(text)

def main():
    morty = MortyAssistant()
    device = get_input_device()
    
    say_morty('greeting')
    
    with sd.RawInputStream(device=device,
                          samplerate=16000,
                          blocksize=8000,
                          dtype='int16',
                          channels=1,
                          callback=callback):
        while True:
            global last_response_time
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞
            if time.time() - last_response_time > 10 and last_response[0]:
                say_morty('error', last_response[1])
            
            try:
                text = q.get(timeout=1)
                print("üì• –¢—ã —Å–∫–∞–∑–∞–ª:", text)
                if not morty.handle_command(text):
                    break
            except queue.Empty:
                continue

if __name__ == '__main__':
    main()

