import json
import queue
import random
import requests
import sounddevice as sd
import pyttsx3
from vosk import Model, KaldiRecognizer
import webbrowser
import time

# –ø–æ–¥–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ vosk
recognizer = KaldiRecognizer(Model("model"), 16000)
audio_queue = queue.Queue() 

# –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ TTS
tts_engine = pyttsx3.init() # –∏–Ω–∏—Ç –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞
tts_engine.setProperty('rate', 180) #c–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ –ú–æ—Ä—Ç–∏
is_speaking = False
last_speech_time = 0  # –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏

MORTY_PHRASES = {
    'greeting': [
        "–≠-—ç–º... –ø—Ä–∏–≤–µ—Ç, –†–∏–∫! –Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ... –Ω–∞–≤–µ—Ä–Ω–æ–µ",
        "–û–∫–µ–π, —è –≤–∫–ª—é—á–∏–ª—Å—è... —Ç–æ–ª—å–∫–æ –Ω–µ –æ—Ä–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
        "–°–Ω–æ–≤–∞ —Ä–∞–±–æ—Ç–∞–µ–º? –õ–∞–¥–Ω–æ... —è –≥–æ—Ç–æ–≤, –≤—Ä–æ–¥–µ"
    ],
    'error': [
        "–ß-—á—Ç–æ? –Ø –Ω–µ –ø–æ–Ω—è–ª... –ø–æ–≤—Ç–æ—Ä–∏ –º–µ–¥–ª–µ–Ω–Ω–µ–µ!",
        "–≠-—ç—Ç–æ –≤–æ–æ–±—â–µ –ø–æ-—Ä—É—Å—Å–∫–∏? –Ø –∑–∞–ø—É—Ç–∞–ª—Å—è...",
        "–†–∏–∫, —è –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å... –º–æ–∂–µ—Ç, –ø–æ–≤—Ç–æ—Ä–∏—à—å?"
    ],
    'result': [
        "–í–æ—Ç —á—Ç–æ —è –Ω–∞—à—ë–ª: {result}... —ç—Ç–æ —Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ?",
        "–ö–∞–∂–µ—Ç—Å—è, —ç—Ç–æ {result}... –Ω–∞–¥–µ—é—Å—å, —è –Ω–µ –æ—à–∏–±—Å—è",
        "–°–º–æ—Ç—Ä–∏, –†–∏–∫! {result}... –∫—Ä—É—Ç–æ, –¥–∞?"
    ],
    'action': [
        "–î–µ–ª–∞—é... —ç-—ç–º... —Ç–æ–ª—å–∫–æ –Ω–µ –≤–∑–æ—Ä–≤–∏ –Ω–∏—á–µ–≥–æ!",
        "–ü—ã—Ç–∞—é—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å... –æ –±–æ–∂–µ, —ç—Ç–æ —Å—Ç—Ä–∞—à–Ω–æ",
        "–©–∞ —Å–¥–µ–ª–∞—é... –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ —É–±–∏–≤–∞–π –º–µ–Ω—è"
    ],
    'exit': [
        "–§—É—Ö... –Ω–∞–∫–æ–Ω–µ—Ü-—Ç–æ –∑–∞–∫–æ–Ω—á–∏–ª–∏! –Ø —É—Å—Ç–∞–ª...",
        "–í—ã—Ä—É–±–∞—é—Å—å... –µ—Å–ª–∏ —á—Ç–æ, —è –≤ —Å–≤–æ–µ–π –∫–æ–º–Ω–∞—Ç–µ",
        "–ü–æ–∫–∞, –†–∏–∫! –ù–∞–¥–µ—é—Å—å, —è –Ω–µ –Ω–∞–∫–æ—Å—è—á–∏–ª..."
    ]
}

def audio_callback(indata, frames, time, _):#–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –º–∏–∫—Ä–æ
    data = bytes(indata) # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–∞—Å—Å–∏–≤ –±–∞–π—Ç (–¥–ª—è Vosk)
    if recognizer.AcceptWaveform(data):
        result = json.loads(recognizer.Result()) #—Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–æ–≤–∞–Ω–∏—è
        if result.get("text"):  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–∞
            audio_queue.put(result["text"])


def say_morty(key, result=None): #key - —Ç–∏–ø —Ñ—Ä–∞–∑—ã
    global last_speech_time
    phrase = random.choice(MORTY_PHRASES[key]) #—Ä–∞–Ω–¥–æ–º–Ω–∞—è —Ñ—Ä–∞–∑–∞ –ø–æ –∫–ª—é—á—É
    if result:
        phrase = phrase.format(result=result)

    print("ü§Ø", phrase)
    tts_engine.say(phrase)  # —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏
    tts_engine.runAndWait()  # –æ–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–∏–Ω—Ç–µ–∑–∞
    last_speech_time = time.time()  # –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ—á–∏

class MortyAssistant:
    def __init__(self):
        self.current_character = {} # —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç —Ç–µ–∫—É—â –ø–µ—Ä—Å–æ–Ω–∞–∂–µ

    def random_character(self): #–ø–æ–ª—É—á–∞–µ–º —Å–ª—á–∞–π–Ω–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –∏–∑ API 
        say_morty('action')
        char_id = random.randint(1, 826)
        res = requests.get(f"https://rickandmortyapi.com/api/character/{char_id}").json()
        self.current_character = res
        say_morty('result', result=res['name'])

    def show_image(self):
        say_morty('action')
        webbrowser.open(self.current_character["image"])

    def save_image(self):
        say_morty('action')
        img_data = requests.get(self.current_character["image"]).content
        with open("character.png", "wb") as f:
            f.write(img_data)
        say_morty('result', result="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")

    def first_episode(self):
        say_morty('action')
        first_ep = self.current_character["episode"][0]
        ep_data = requests.get(first_ep).json()
        say_morty('result', result=ep_data["name"])

    def get_resolution(self):
        say_morty('action')
        from PIL import Image
        from io import BytesIO
        img_data = requests.get(self.current_character["image"]).content
        img = Image.open(BytesIO(img_data))
        res = f"{img.width}√ó{img.height} –ø–∏–∫—Å–µ–ª–µ–π"
        say_morty('result', result=res)

    def handle_command(self, command):
        cmd = command.lower()
        if '—Å–ª—É—á–∞–π–Ω—ã–π' in cmd:
            self.random_character()
        elif '–ø–æ–∫–∞–∂–∏' in cmd and self.current_character:
            self.show_image()
        elif '—Å–æ—Ö—Ä–∞–Ω–∏' in cmd and self.current_character:
            self.save_image()
        elif '—ç–ø–∏–∑–æ–¥' in cmd and self.current_character:
            self.first_episode()
        elif '—Ä–∞–∑—Ä–µ—à–µ–Ω–∏' in cmd and self.current_character:
            self.get_resolution()
        elif '—Å—Ç–∞—Ç—É—Å' in cmd and self.current_character:
            status = self.current_character.get('status', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')
            say_morty('result', result=f"–µ–≥–æ —Å—Ç–∞—Ç—É—Å ‚Äî {status}")
        elif '–ª–æ–∫–∞—Ü–∏' in cmd and self.current_character:
            location = self.current_character.get('location', {}).get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ª–æ–∫–∞—Ü–∏—è')
            say_morty('result', result=f"–æ–Ω –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ {location}")
        elif '–≥–¥–µ –æ–Ω –±—ã–ª' in cmd and self.current_character:
            episodes = self.current_character.get('episode', [])
            num = len(episodes)
            say_morty('result', result=f"–æ–Ω –ø–æ—è–≤–∏–ª—Å—è –≤ {num} —ç–ø–∏–∑–æ–¥–∞—Ö")
        elif '–≤—ã—Ö–æ–¥' in cmd or '—Å—Ç–æ–ø' in cmd:
            say_morty('exit')
            return False
        else:
            say_morty('error')
        return True

def main():
    morty = MortyAssistant()
    device = 1 #–º–∏–∫—Ä–æ—Ñ–æ–Ω
    
    say_morty('greeting')
    
    with sd.RawInputStream( # —Å—á–∏—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ
        device=device,
        samplerate=16000,
        blocksize=8000,
        dtype='int16',
        channels=1,
        callback=audio_callback
    ):
        while True:
            global last_speech_time
           
            try:
                text = audio_queue.get(timeout=1)
                
                # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—ã, –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ –º–µ–Ω—å—à–µ 2 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ—á–∏
                if time.time() - last_speech_time < 2:
                    continue
                
                if text.strip():  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è
                    print("üíÄ –†–∏–∫:", text)
                    if not morty.handle_command(text):
                        break
                else:
                    say_morty('error')
            except queue.Empty:
                continue

if __name__ == '__main__':
    main()